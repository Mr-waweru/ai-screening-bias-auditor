# AI Screening Bias Auditor 

## Introduction & Problem Statement


AI Screening Bias Auditor is a Generative AIâ€“powered system designed to detect, measure, and report bias in AI-based resume screening tools. As organizations increasingly adopt automated hiring systems, concerns have grown about algorithmic discrimination, where candidates may be unfairly rejected due to gender, race, age, religion, or geographic origin; even when these attributes are not explicitly provided. This project addresses that challenge by building an automated, multi-agent auditing system that evaluates how fair and unbiased AI hiring tools truly are.
The project leverages Generative AI, Jaclang architecture, and byLLM workflows to generate counterfactual resumes, run them through target screening systems, measure bias, and generate interpretable audit reports.

## Industry Relevance
* Regulatory Bodies & Government Agencies.
* Companies that build and sell Applicant Tracking Systems (ATS) and AI screening tools - Vendors can use this tool's certification as a selling point, marketing their product as a "Bias-Audited" solution to ethical enterprises.
* Ethical Corporations & Chief Diversity Officers (CDOs)
* Independent AI Auditors & Consultants
